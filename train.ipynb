{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from models import *\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    def __init__(self, root=r'data', w=144, h=144, transform=None,is_train=0):\n",
    "        file = os.listdir(root)\n",
    "\n",
    "        imgs = []\n",
    "        # 每张图\n",
    "        for line in file:\n",
    "            imgs.append((os.path.join(root, line, 'img.png'), os.path.join(root, line, 'label.png')))\n",
    "        # 对于特定类别的，在加一次\n",
    "        if is_train:\n",
    "            for line in file:\n",
    "                if  line == '20220623163957' or line == '20220623164000' or line == '20220623164006':\n",
    "                    imgs.append((os.path.join(root, line, 'img.png'), os.path.join(root, line, 'label.png')))\n",
    "            for line in file:\n",
    "                if  line == '20220623164013' or line == '20220623164024' or line == '20220623164006':\n",
    "                    imgs.append((os.path.join(root, line, 'img.png'), os.path.join(root, line, 'label.png')))\n",
    "            for line in file:\n",
    "                if line == '20220623164013':\n",
    "                    imgs.append((os.path.join(root, line, 'img.png'), os.path.join(root, line, 'label.png')))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.width = w\n",
    "        self.height = h\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imagename, labelname = self.imgs[index]\n",
    "        img = Image.open(imagename)\n",
    "        img = img.resize((self.width, self.height))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        mask = Image.open(labelname)\n",
    "        mask = mask.resize((self.width, self.height))\n",
    "        target = np.array(mask).astype('int32')\n",
    "        target[target == 255] = -1\n",
    "        return img, torch.from_numpy(target).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, optimizer,scheduler, loss_fun,device):\n",
    "    # set model to train mode\n",
    "    net.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for inputs, labels in (train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        out = net(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        # print(out.shape,labels.shape)\n",
    "        loss = loss_fun(out, labels)\n",
    "        train_loss += loss.item()/len(labels)\n",
    "        \n",
    "        pred = torch.max(out, 1)[1]\n",
    "        train_correct = (pred == labels).sum() / (labels.shape[-1] * labels.shape[-2])\n",
    "\n",
    "        train_acc += train_correct.item()/len(labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() #每个epoch后的所有batch完成，更新学习率\n",
    "    torch.save(net.state_dict(),  'net.pth')\n",
    "    return train_acc / len(train_loader) ,train_loss / math.ceil(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader,loss_func, net,device):\n",
    "    # set model to eval mode\n",
    "    net.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in (test_loader):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            out = net(inputs)\n",
    "            loss = loss_func(out, labels)\n",
    "            eval_loss += loss.item()/len(labels)\n",
    "            pred = torch.max(out, 1)[1]\n",
    "            num_correct = (pred == labels).sum() /  (labels.shape[-1] * labels.shape[-2])\n",
    "            eval_acc += num_correct.item()/len(labels)\n",
    "            \n",
    "    return eval_acc / (len(test_loader)),eval_loss / math.ceil(len(test_loader) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Unet(3,4)\n",
    "# model=FCN32s(4)\n",
    "# model=Net_seg(4)\n",
    "net = model.cuda()\n",
    "device=\"cuda\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [10, 20], 0.1)#调整学习率\n",
    "loss = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "width = 500\n",
    "height = 500\n",
    "batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "train_data = SegDataset(root=r'data', w=width, h=height, transform=train_transforms,is_train=1)\n",
    "val_data = SegDataset(root=r'data', w=width, h=height, transform=train_transforms)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14952\\3827355863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtemp_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14952\\893333318.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, optimizer, loss_fun, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# print(out.shape,labels.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc=[]\n",
    "test_acc=[]\n",
    "train_loss=[]\n",
    "test_loss=[]\n",
    "epoch=1000\n",
    "max_acc=0\n",
    "for i in (range(epoch)):\n",
    "    temp_acc,temp_loss=train(train_loader, net, optimizer,scheduler, loss,device)\n",
    "    train_acc.append(temp_acc)\n",
    "    train_loss.append(temp_loss)\n",
    "\n",
    "    temp_acc,temp_loss=test(test_loader,loss, net,device)\n",
    "    test_acc.append(temp_acc)\n",
    "    test_loss.append(temp_loss)\n",
    "    if temp_acc>=max_acc:\n",
    "        max_acc=temp_acc\n",
    "        torch.save(model.state_dict(),  'best.pth')\n",
    "    print(\"Epoch: %d  Train Loss: %.3f, Acc: %.3f\"%(i+1,train_loss[i],train_acc[i]))\n",
    "    print(\"Epoch: %d  Test Loss: %.3f, Acc: %.3f\\n\"%(i+1,test_loss[i],test_acc[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96d32af43df8805957db0e5fc6e5fcf3acc7686f781ef48b23e746feb670d8e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
